<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<title>Transformer ID</title>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
	<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
	<style>
		body {
			color: White;
			background-color: #26292B;
			min-height: 100vh;
			width: 95%;}	
		
		#main_title {
			border-radius: 25px;
			display: flex;
			flex-direction: row;
			text-align: left;
			margin: 0% 5% 2% 5%;
			background-color: #5F7ADB;
			width: 90%;}
		
		#menu_holder{
			display: flex;
			flex-direction: row;}
			
		.menu_box {
			border-radius: 25px;
			margin: 0% 2% 0% 2%;
			text-align: center;
			background-color: #DFFF00;
			width: 30%;}

		#drop_div {
			border-radius: 25px;
			margin: 0% 2% 0% 2%;
			text-align: center; 
			align-content: center;
			color: #000000;
			background-color: #F8F0E3;
			width: 80%;
			height: 200px;}
		
		#drop_box {
			text-align: center;}
		
		#image_input {
			margin: 2%;}
		
		#placeholder {
			max-height: 300px;}
		
		#user_image {
			text-align: center;
			font-size: 25px;
			font-weight: bold;}
		
		#report {
			text-align: left;}
		
		#process_image_b {
			width: 80%;
			height: 60px;
			text-align: center;
			align-content: center;
			border-radius: 25px;
			background-color: #DFFF00;}
		
		#canvas_img{
			display: none;}
		
		#preview {
			width: 300px;}
		
		#capture_fake_button {
			color: White;
			background-color: #26292B;
			text-align: center;}
				
		#intro {
			width: 100%;}

		#main_flex {
			position: relative;
			display: flex;
			flex-direction: row;
			width: 100%;}

		#flex_div1 {
			width: 50%;
			text-align: center;
			align-items: center;
			justify-content: center;
			display: flex;
			flex-direction: column;
			z-index: 0;}

		#flex_div2 {
			width: 50%;
			text-align: center;
			display: flex;
			flex-direction: column;
			z-index: 0;}
		
		#float_div {
			position: absolute;
			top: 10%;
			left: 40%;
			z-index: 1;
			width: 300px;
			background-color: #000000;
			display: none;}
		
		.upload_flex_div {
			width: 90%;
			text-align: center;
			text-wrap: pretty;
			display: flex;
			flex-wrap: wrap;
			flex-direction: column;
			border-radius: 25px; 
			border: 5px solid #FF00FF;
			margin: 2% 2% 2% 2%;
			padding: 2%;
			align-content: space-around;
			justify-content: space-evenly;
		}
		
		#capture_div {
			position: absolute;
			top: 10%;
			left: 40%;
			z-index: 1;
			width: 300px;
			border: 5px solid #000000;
			display: none;
			background-color: #26292B;}
			
		input::-webkit-outer-spin-button,
		input::-webkit-inner-spin-button {
  		-webkit-appearance: none;
  		margin: 0;}

		input[type=number] {
			text-align: center; 
			-moz-appearance: textfield;}
		
		button {text-align: center;
			}

		hr {color: white;}
	</style>
</head>

<body>
	<div id="main_title"> <img  style="padding: 2% 1% 1% 5%;" src="images/comp_chem_2_small.jpg" alt="Computer"> 
		<h1 style="padding: 50px;">Who's that Transformer??!!?? <br>Neural Network identification of your favorite Autobots and Decepticons!</h1>
	</div>
	
	<div id="menu_holder">
		<a class="menu_box" href="Chem_webapps_frontpage.html" style="color: #00008B;">Back to Chemistry Web Apps</a>
	</div>
	<br>

	<div id="intro">
		<ul>
			<li>Are you having trouble identifying your favorite Transformer? Use this neural network to identify it!</li>
			<li>Upload a picture or take a picture with your mobile device, or even use a webcam on a desk/laptop.</li>
			<li>The model will run and see if it's Optimus, Megatron, Soundwave or Bumblebee!</li>
			<li>The model works best on pictures of toys in robot mode. I've had near 100% accuracy for the four characters above, regardless of toyline 
			(vintage, generations, RID, Cyberverse, etc). Works okay for illustration/screen caps of characters.</li>
			<li>Bumblebee and Soundwave (and maybe Optimus) should work in alt mode as well.</li> 
			<li>The Tensorflow model, MobileNet, is used as a base and it is fine-tuned to recognize transformers. </li>
			<li>If you have any requests for figures to add, drop a comment at my Github repository: 
			<a href="https://github.com/MauricioCafiero/Chemistry-and-Machine-Learning-WebApps-in-Javascript"> here!</a></li>
		</ul>
	</div>
	<hr>
	<section id = "main_flex">
		<div id = "flex_div1">
			
			<label id="drop_box">
				<div id="drop_div" style="margin: auto;"> Drag and drop your image of a Transformer here! </div>
			</label>
			<div class="upload_flex_div">
				<span>or use this button to upload an image or to use your <strong><big>mobile camera:</big></strong></span>
				<input type="file" id="image_input" accept="image/*">
			</div>
				
			<div class="upload_flex_div">
				<label>or use this to capture an image with your <strong><big>webcam (desktop):</big></strong></label>
				<button id="capture_image_b" onclick="capture_image()">Capture image from camera.</button>
			</div>
				
		</div>
		
		<div id = "flex_div2">
			<span id = "user_image">Your image will appear below.</span><br>
			<div id="image_holder"><img id = "placeholder" src = "images/genericon.jpg"></div>
			<div id="report"></div>
		</div>
		
		<div id="float_div"><img id = "waiting" src = "images/roboquest.jpg"></div>
		<div id="capture_div">
		<span id="capture_fake_button">Click here to capture</span>
		<video id="preview"></video>
		</div>
		<canvas id="canvas_img"></canvas>
	</section>
	<hr>
	<p>This is the work of Dr. Mauricio Cafiero and may be used widely though attribution is appreciated.</p>

</body>

<script>

console.log(tf.version.tfjs);

// define global variables ================================================================================================

document.getElementById("drop_box").addEventListener('drop', event => {
	event.preventDefault();
	const [item] = event.dataTransfer.items;
	const file = item.getAsFile();
	
	if (file.type.startsWith('image/')) {
		show_dropped_image(file);
		const text_over = document.getElementById("user_image");
		text_over.innerHTML = "This is your image!";
		const report = document.getElementById("report");
		report.innerHTML = "";
		process_image();
		
}});

document.getElementById("drop_box").addEventListener('dragover', event => {
	event.preventDefault();});

document.getElementById("capture_fake_button").addEventListener('click', event => {
	capture();});
	
var file_input = document.getElementById("image_input");

file_input.addEventListener('change', () => {
	const [file] = file_input.files;
	show_dropped_image(file);
	
	const text_over = document.getElementById("user_image");
	text_over.innerHTML = "This is your image!";
	
	const report = document.getElementById("report");
	report.innerHTML = "";
	process_image();
	
	});

function show_dropped_image(file) {
	const reader = new FileReader();
	
	reader.addEventListener('load',event => {
		const image = document.getElementById("placeholder");
		image.src = event.target.result;});
	
	reader.readAsDataURL(file);
}

async function process_image() {
	
	const waiting = document.getElementById("float_div");
	waiting.style.display="Block";
	
	try {
		const modelURL = "https://teachablemachine.withgoogle.com/models/BSYvkfPwS/model.json";
		const metadataURL = "https://teachablemachine.withgoogle.com/models/BSYvkfPwS/metadata.json";
		model = await tmImage.load(modelURL, metadataURL);
		var maxPredictions = model.getTotalClasses();
		console.log(`The total classes in the model are: ${maxPredictions}`);
	} catch {
		alert("Could not load model!");
	}
	
	const beaker = document.getElementById("placeholder");
	beaker.crossOrigin = "Anonymous";
	var predictions = await model.predict(beaker,false);
	parse_predictions(predictions);
	
}

function parse_predictions(predictions) {
	things = new Array();
	probabilities = new Array();
	
	const waiting = document.getElementById("float_div");
	
	waiting.style.display = "None";
	
	const report = document.getElementById("report");
	report_text = "<strong>What it could be:</strong><hr>";

	predictions.forEach(dictionary => {
		things.push(dictionary.className);
		probabilities.push(dictionary.probability);
		prob = Math.round(100*dictionary.probability);
		report_text += `${dictionary.className} : ${prob} % <br>`
	}
	);
	const text_over = document.getElementById("user_image");
	
	likely = Math.max(...probabilities);
	likely_index = probabilities.findIndex(x => x == likely);
	which_thing = things[likely_index];
	likely = Math.round(100*likely);
	
	beaker_string = `Your picture is most likely ${which_thing}, with a percent probability of ${likely} %<br>`
	text_over.innerHTML = beaker_string;
	report.insertAdjacentHTML("beforeEnd",report_text);
}

function capture_image() {
	const capture_div = document.getElementById("capture_div");

	capture_div.style.display = "Block";
	start_camera();
}

async function start_camera() {
	const preview = document.getElementById("preview");
	const stream = await navigator.mediaDevices.getUserMedia({
		video: true,
		audio: false}).then((stream) => {
			preview.srcObject = stream;
			preview.play();})
  .catch((err) => {
    console.error(`An error occurred: ${err}`);
  });
}

function capture() {
	const canvas_img = document.getElementById("canvas_img");
	const photo = document.getElementById("placeholder");
	const preview = document.getElementById("preview");
	
	canvas_img.width = canvas_img.width * window.devicePixelRatio;
	canvas_img.height = canvas_img.height * window.devicePixelRatio;
	
	const c = canvas_img.getContext("2d");
	c.drawImage(preview,0,0,canvas_img.width,canvas_img.height);
	
	const dataURL = canvas_img.toDataURL("image/jpeg");
	photo.setAttribute("src", dataURL);
	
	const capture_div = document.getElementById("capture_div");
	capture_div.style.display = "None";
	
	const text_over = document.getElementById("user_image");
	text_over.innerHTML = "This is your image!";
	
	const report = document.getElementById("report");
	report.innerHTML = "";
	
	stopStreamedVideo(preview);
	
	process_image();
}

function stopStreamedVideo(videoElem) {
  const stream = videoElem.srcObject;
  const tracks = stream.getTracks();

  tracks.forEach((track) => {
    track.stop();
  });

  videoElem.srcObject = null;
}

</script>

</html>